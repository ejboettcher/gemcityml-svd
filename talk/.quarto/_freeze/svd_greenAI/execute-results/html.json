{
  "hash": "11e122bc78999b61cc23dfb1bd87939d",
  "result": {
    "markdown": "---\ntitle: \"Linear Algebra for ML/AI aka Green AI\"\nsubtitle: \"Welcome\"\ndate: \"20231019\"\nauthor: \"Presented by Evelyn J. Boettcher\"\ntitle-slide-attributes:\n    data-background-image: 'img/logos/gem_cityML_slide.png'\n    data-background-size: \"100% 100% \"\n    data-background-position: \"0% \"\n    data-background-opacity: \"0.95\"\nformat:\n    revealjs:\n        incremental: false\nfig-cap-location: margin\n\n---\n\n## Ax-b = 0\n### System of Linear Equations\n\nSolving a  system of linear equations is fast. \n\n<br>\n<br>\nIt can easily and quickly handle large data. \n\n<br>\n\nSo if you can get your problems into the `Ax=b` form; your golden.\n\n---\n\n## Ax=b, in action\n#### System of linear equations\n\n```bash\n3x + 4y = 19\n2y + 3z = 8\n4x - 5z = 7\n```\n\n<br>\n\n#### In Matrix form\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n$$\nA = \\begin{bmatrix}\n     3 & 4 & 0\\\\\n     0 & 2 & 3 \\\\\n     4 & 0 & -5\n    \\end{bmatrix}\n$$\n\n:::\n\n::: {.column width=\"50%\"}\n\n$$\nb = \\begin{bmatrix}\n   19 \\\\\n    8\\\\\n   7\n  \\end{bmatrix}\n$$\n\n:::\n::::\n\n---\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n$$\nA = \\begin{bmatrix}\n     3 & 4 & 0\\\\\n     0 & 2 & 3 \\\\\n     4 & 0 & -5\n    \\end{bmatrix}\n$$\n\n:::\n\n::: {.column width=\"50%\"}\n\n$$\nb = \\begin{bmatrix}\n   19 \\\\\n    8\\\\\n   7\n  \\end{bmatrix}\n$$\n\n:::\n::::\n\n\n#### Solve with python\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nA = np.array([[3, 4, 0],\n              [0, 2, 3], \n              [4, 0, -5]])\nB = np.array([19, 8, 7])\n# Using np built-in linear equation solver\nx = np.linalg.solve(A,B)\nprint( tuple(x))\n# WOW that was easy.\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(3.0, 2.5, 1.0)\n```\n:::\n:::\n\n\n---\n\n## What if you don't have a \"Full Rank\" matrix\n### Or systems that can be fulled solved?\n\nThis is where **SVD** (Single Value Decomposition) comes to the rescue. <br>\n\nBeyond solving a system of linear equations. \n\n<br>\nIt is used for:\n\n* It is used to compress images\n* Find main features (see compressed images)\n* for fitting Polynomial.\n* Predict Sun spots activity\n\nAs long as you can get your problem into the `Ax=b` form.\n\n---\n\n## SVD\n\nSingular value decomposition (SVD) is a factorization of a real or complex matrix. \n\n<br>\n\nSVD of Matrix A is: <br>\n\n* SVD(A) = $U \\Sigma V^T$ \n\n<br>\n\nSo when we system that can be written as: `Ax=b`\n\n* We can solve for x by:\n\n$$\nx^\\prime = V \\Sigma U^T b\n$$\n\nThen $x^\\prime$ is the solution that has the minimum norm (closest to origin).\nIf it is not in the range, then it is the least-squares solution.\n\n---\n\n## Wow that was clear.\n\nTake a minute and google how to multiply matrixs\n\n<br>\n<br>\n\nGreat resource: [SVD Tutorial](https://sthalles.github.io/svd-for-regression/)\n\n\n\n## Sun Spots predictions\n\nThere exists a data set that contains the number of sun spots observed for a given month, spanning hundreds of years.\n<br>\n<br>\n\n[https://github.com/ejboettcher/GemCity-ML-AI_Random](https://github.com/ejboettcher/GemCity-ML-AI_Random)\n\n<br>\n<br>\n\nIn the above tutorial, I used tensorflow, WITH GPU and it took several minutes to train the algorithm to predict sunspot activity.\nAnd it was good.\n\n<br>\n<br>\n\n### Can SVD predict sunspot activity and faster?\n\n* Yes\n* Yes\n\n---\n\n## Blindly use an SVD\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nsunspot_data = pd.read_csv(\"data/Sunspots.csv\")\nsunspot_data['time'] = pd.to_datetime(sunspot_data['Date'], format='%Y-%m-%d')\nnname = 'Monthly Mean Total Sunspot Number'\n\nwindow = 1\ndataset = np.ones((len(sunspot_data)-window, window))\nfor ii in range(len(dataset)):\n    dataset[ii,:] = sunspot_data.loc[ii:ii+window-1, nname].to_numpy().T\n\nA = dataset\nA = np.column_stack([np.ones(A.shape[0]), A])\nb = sunspot_data.loc[window:, nname].to_numpy()\n\n# calculate the economy SVD for the data matrix A\nU,S,Vt = np.linalg.svd(A, full_matrices=False)\n\n# solve Ax = b for the best possible approximate solution in terms of least squares\nx_hat = Vt.T @ np.linalg.inv(np.diag(S)) @ U.T @ b\n\n# perform train and test inference\nb_pred = A @ x_hat\n\ntrain_data = pd.DataFrame({'time':sunspot_data.loc[window:,'time'],\n                           'b':b, \n                           'b_pred':b_pred} )\ntrain_data.plot(x='time', y=['b', 'b_pred'])\n\n# compute train and test MSE\ntrain_mse = np.mean(np.sqrt((b_pred - b)**2))\nprint(\"Train Mean Squared Error:\", train_mse)\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain Mean Squared Error: 19.273508962865446\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](svd_greenAI_files/figure-revealjs/cell-3-output-2.png){width=798 height=422}\n:::\n:::\n\n\n---\n\n## More features\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nsunspot_data = pd.read_csv(\"data/Sunspots.csv\")\nsunspot_data['time'] = pd.to_datetime(sunspot_data['Date'], format='%Y-%m-%d')\nnname = 'Monthly Mean Total Sunspot Number'\n\nwindow = 12\ndataset = np.ones((len(sunspot_data)-window, window))\nfor ii in range(len(dataset)):\n    dataset[ii,:] = sunspot_data.loc[ii:ii+window-1, nname].to_numpy().T\n\nA = dataset\nA = np.column_stack([np.ones(A.shape[0]), A])\nb = sunspot_data.loc[window:, nname].to_numpy()\n\n# calculate the economy SVD for the data matrix A\nU,S,Vt = np.linalg.svd(A, full_matrices=False)\n\n# solve Ax = b for the best possible approximate solution in terms of least squares\nx_hat = Vt.T @ np.linalg.inv(np.diag(S)) @ U.T @ b\n\n# perform train and test inference\nb_pred = A @ x_hat\n\ntrain_data = pd.DataFrame({'time':sunspot_data.loc[window:,'time'],\n                           'b':b, \n                           'b_pred':b_pred} )\ntrain_data.plot(x='time', y=['b', 'b_pred'])\n\n# compute train and test MSE\ntrain_mse = np.mean(np.sqrt((b_pred - b)**2))\nprint(\"Train Mean Squared Error:\", train_mse)\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain Mean Squared Error: 17.875197212239335\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](svd_greenAI_files/figure-revealjs/cell-4-output-2.png){width=798 height=422}\n:::\n:::\n\n\n---\n\n## Prove it on data it has not seen.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nsplit_num = 3000\nA = dataset\nA = np.column_stack([np.ones(A.shape[0]), A])\nX_train = A[:split_num,:]\ny_train = sunspot_data.loc[window:split_num+window-1, nname].to_numpy()\n\nX_test = A[split_num:,:]\ny_test = sunspot_data.loc[split_num+window:, nname].to_numpy()\n\nprint(X_test.shape, y_test.shape, X_train.shape, y_train.shape)\n# calculate the economy SVD for the data matrix A\nU,S,Vt = np.linalg.svd(X_train, full_matrices=False)\n\n# solve Ax = b for the best possible approximate solution in terms of least squares\nx_hat = Vt.T @ np.linalg.inv(np.diag(S)) @ U.T @ y_train\n\n# perform train and test inference\ny_pred = X_train @ x_hat\ntest_predictions = X_test @ x_hat  # This is the MAGIC\n\ntest_data =  pd.DataFrame({'time':sunspot_data.loc[split_num+window:,'time'],\n                           'test':y_test, \n                           'y_pred':test_predictions} )\ntest_data.plot(x='time', y=['test', 'y_pred'])\n\n\n# compute train and test MSE\ntrain_mse = np.mean(np.sqrt((y_pred - y_train)**2))\ntest_mse = np.mean(np.sqrt((test_predictions - y_test)**2))\n\nprint(\"Train Mean Squared Error:\", train_mse)\nprint(\"Test Mean Squared Error:\", test_mse)\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(223, 13) (223,) (3000, 13) (3000,)\nTrain Mean Squared Error: 18.20793849887562\nTest Mean Squared Error: 13.688869408003756\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](svd_greenAI_files/figure-revealjs/cell-5-output-2.png){width=798 height=422}\n:::\n:::\n\n\n---\n\n## What, explain again what an SVD does.\n\nLet's take a look at how SVD can be used for image compression.\n\n<br>\n(tutorial)[https://sthalles.github.io/svd-for-regression/]\n\n\n---\n\n## Thank you\n\nSVD can just do it.  You just need to get it into the Ax=B form.\n\n",
    "supporting": [
      "svd_greenAI_files"
    ],
    "filters": [],
    "includes": {}
  }
}